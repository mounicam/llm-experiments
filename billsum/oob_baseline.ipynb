{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a86d045-cc0a-4955-9283-8b42c799109c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2026-01-25 16:24:15.533005: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1769358255.551880   13025 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1769358255.558016   13025 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1769358255.576301   13025 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769358255.576315   13025 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769358255.576318   13025 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769358255.576319   13025 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "# 1. Initialize the pipeline\n",
    "summarizer = pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=\"google/gemma-3-1b-it\",\n",
    "    device=0,\n",
    "    torch_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6405717-83f3-4d93-9202-4670541a32f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "input_file = \"billsum_v4_1/org_with_cefr_labels/us_test.jsonl\"\n",
    "dataset = [json.loads(line.strip()) for line in open(input_file)]\n",
    "print(dataset[0]['text'])\n",
    "dataset = dataset[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "386776d8-f71a-4af2-8080-f7bfe420d819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'system_prompt': 'You are helpful assistant designed to make English legal text more readable for different target audience at different CEFR readability levels.', 'user_prompt': 'Summarize the following text for a {{ level }} reader. {{ text }} \\n Please output the summary as a paragraph.'}\n",
      "<Template memory:705c159ebd00>\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from jinja2 import Template\n",
    "\n",
    "prompt_file = \"summarization_prompt.json\"\n",
    "prompt_json = json.loads(open(prompt_file).read().strip())\n",
    "print(prompt_json)\n",
    "\n",
    "jinja_template = Template(prompt_json[\"user_prompt\"])\n",
    "print(jinja_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58015ccc-37a7-4162-a36e-66cdd0f39edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import pipeline\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# cefr_labels = [\"A1\", \"A2\", \"B1\", \"B2\", \"C1\", \"C2\"]\n",
    "\n",
    "# for i in tqdm(range(len(dataset))):\n",
    "    \n",
    "#     text = dataset[i][\"text\"]\n",
    "#     messages = [\n",
    "#             [\n",
    "#                 {\n",
    "#                     \"role\": \"system\",\n",
    "#                     \"content\": [{\"type\": \"text\", \"text\": prompt_json[\"system_prompt\"]},]\n",
    "#                 },\n",
    "#                 {\n",
    "#                     \"role\": \"user\",\n",
    "#                     \"content\": [{\"type\": \"text\", \"text\": jinja_template.render(text=text, level=label)},]\n",
    "#                 },\n",
    "#             ]\n",
    "#         for label in cefr_labels\n",
    "#     ]\n",
    "\n",
    "#     summaries = summarizer(messages, max_new_tokens=512, batch_size=6)\n",
    "\n",
    "#     all_summaries = {}\n",
    "#     for summary, label in zip(summaries, cefr_labels):\n",
    "#         summary_text = summary[-1][\"generated_text\"][-1][\"content\"]\n",
    "\n",
    "#         summary_text = summary_text.split(\"\\n\\n\")\n",
    "#         summary_text = \"\\n\\n\".join(summary_text[1:])\n",
    "\n",
    "#         all_summaries[label] = summary_text\n",
    "\n",
    "#     dataset[i][\"predictions\"] = all_summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac1a59f-4cc1-4ed5-a412-9891ac7705e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "cefr_labels = [\"A1\", \"A2\", \"B1\", \"B2\", \"C1\", \"C2\"]\n",
    "\n",
    "# 1. Flatten the dataset into \"Task Rows\"\n",
    "# Each row in 'flat_data' will represent ONE summary task\n",
    "flat_data = []\n",
    "for item in dataset:\n",
    "    for label in cefr_labels:\n",
    "        # Pre-render the messages\n",
    "        msg = [\n",
    "            {\"role\": \"system\", \"content\": prompt_json[\"system_prompt\"]},\n",
    "            {\"role\": \"user\", \"content\": jinja_template.render(text=item[\"text\"], level=label)}\n",
    "        ]\n",
    "        flat_data.append({\"messages\": msg})\n",
    "\n",
    "# 2. Use a Generator to stream data (prevents the 'sequential' warning)\n",
    "def data_generator():\n",
    "    for item in flat_data:\n",
    "        # print(item)\n",
    "        yield item[\"messages\"]\n",
    "\n",
    "# 3. Run the pipeline (Properly configured)\n",
    "# 'batch_size' goes here, NOT in model_kwargs\n",
    "summaries = []\n",
    "for out in tqdm(summarizer(data_generator(), batch_size=32, max_new_tokens=512), total=len(flat_data)):\n",
    "    # Extract the text content from the pipeline output\n",
    "    summary_text = out[-1][\"generated_text\"][-1][\"content\"]\n",
    "    \n",
    "    # Cleaning logic (removing the preamble if exists)\n",
    "    # parts = summary_text.split(\"\\n\\n\")\n",
    "    # cleaned = \"\\n\\n\".join(parts[1:]) if len(parts) > 1 else summary_text\n",
    "    summaries.append(summary_text)\n",
    "\n",
    "# 4. Re-shape the results back into your original 18,948 dataset rows\n",
    "for i in range(len(dataset)):\n",
    "    start_idx = i * 6\n",
    "    end_idx = start_idx + 6\n",
    "    # Map the 6 sequential summaries back to their CEFR labels\n",
    "    dataset[i][\"predictions\"] = dict(zip(cefr_labels, summaries[start_idx:end_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2807a9e2-d430-4566-9b85-0a093132492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6077aa96-2532-48d0-a8be-eaf206181681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "output_file = \"billsum_v4_1/predictions/oob/us_test.jsonl\"\n",
    "\n",
    "with open(output_file, \"w\") as fp:\n",
    "    for instance in dataset:\n",
    "        fp.write(json.dumps(instance).strip() + \"\\n\")\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
