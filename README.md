# llm-experiments

Collection of language model fine-tuning experiments focused on text complexity and readability tasks.

## Projects

### 1. BillSum CEFR-Level Summarization (`billsum/`)

Multi-level text summarization of US Congressional bills using reinforcement learning techniques to generate summaries at different CEFR (Common European Framework of Reference) readability levels.

**Goal**: Fine-tune Gemma models to generate legislative summaries tailored to different reading proficiency levels (A, B, C).

See `billsum/README.md` for detailed results and experiment documentation.

### 2. README Sentence Complexity Rating (`readme/`)

Fine-tuning language models to assess the complexity of English sentences on a scale from 1 to 6, given their context.

**Goal**: Train models to rate sentence complexity for language learning applications.
